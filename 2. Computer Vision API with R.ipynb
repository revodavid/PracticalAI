{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision API\n",
    "\n",
    "This script explores using the Cognitive Services Vision API via its REST API. \n",
    "\n",
    "Here, we'll write an R function to extract a random\n",
    "image from Wikimedia Commons, and another function to generate a caption of the image using the Vision API. You can see the end result in this [blog post](http://blog.revolutionanalytics.com/2018/03/computer-vision-api.html).\n",
    "\n",
    "The concepts are mostly explained as we go, but if you\n",
    "want to find more information, take a look here:\n",
    "\n",
    "* Computer Vision Overview: https://cda.ms/kZ\n",
    "* Computer Vision Documentation: https://cda.ms/m0\n",
    "\n",
    "## Using this Notebook\n",
    "\n",
    "The scripts \n",
    "are provided as Jupyter Notebooks within the [Azure Notebooks](https://notebooks.azure.com/?WT.mc_id=ODSC-workshop-davidsmi) service.\n",
    "You don't need a Microsoft\n",
    "Account to view the scripts, but you will need to set one up and generate keys in Azure\n",
    "to run\n",
    "the examples. All of the examples use free Azure services.\n",
    "\n",
    "If you're new to Jupyter Notebooks, here's a quick intro:\n",
    "\n",
    "1. Click within a cell, and then press `Ctrl+Enter` to run (or render) the current cell.\n",
    "2. You'll see a number to the left of the cell when the computations are complete, like this: `In [1]:`. (The number represents the order of computations.) If there's output, it will print below the cell. You may have to scroll up to see it all.\n",
    "3. Run each cell, in order, from to bottom.\n",
    "4. To download/upload files, return to the [library view](https://notebooks.azure.com/davidsmi/libraries/qcon?WT.mc_id=ODSC-workshop-davidsmi) and use the functions in the toolbar.\n",
    "\n",
    "For more information about Notebooks, check out the [Jupyter Notebook documentation](http://jupyter.readthedocs.io/en/latest/index.html).\n",
    "\n",
    "If you're new to R, you might want to start with this [Introduction to\n",
    "R](https://notebooks.azure.com/davidsmi/libraries/intro-r?WT.mc_id=ODSC-workshop-davidsmi) notebook\n",
    "to get a sense of the language.\n",
    "\n",
    "## First, clone these workshop materials\n",
    "\n",
    "1. Visit https://notebooks.azure.com/davidsmi/libraries/aiforgood\n",
    "\n",
    "    * Sign in with your Microsoft account if needed\n",
    "\n",
    "1. click Clone in the toolbar, to create a copy of the workshop materials in your own Azure Notebooks library.\n",
    "\n",
    "\n",
    "## Connecting to Azure services\n",
    "\n",
    "You will need:\n",
    "\n",
    "1. A [Microsoft account](https://account.microsoft.com/account). You can use an existing Outlook 365\n",
    "or Xbox Live account, or create a new one.\n",
    "\n",
    "1. A Microsoft Azure subscription. If you don't already have an Azure subscription, you can visit\n",
    "[https://cda.ms/kT](https://cda.ms/kT) and also get \\$200 in credits to use with paid services. You'll need to provide\n",
    "a credit or debit card, but everything we'll be doing is free to use. If you're a student, you can \n",
    "also register at [https://cda.ms/kY](https://cda.ms/kY) without a credit card for a \\$100 credit.\n",
    "\n",
    "You'll also need a few other things specific to this workshop. Follow the instructions below to \n",
    "set up everything you need.\n",
    "\n",
    "## Log in to the Azure Portal\n",
    "\n",
    "1. Visit https://portal.azure.com \n",
    "2. Sign in with your Microsoft Account. If you don't have a Microsoft account, use the \n",
    "   links above to create one for free.\n",
    "\n",
    "## Create an Azure Resource Group\n",
    "\n",
    "In Azure, a Resource Group is a collection of services you have created. It groups services\n",
    "together, and makes it easy to bulk-delete things later on. We'll create one for this lab.\n",
    "\n",
    "1. Visit https://portal.azure.com (and sign in if needed)\n",
    "2. Click \"Resource Groups\" in the left column\n",
    "3. Click \"+ Add\"\n",
    "    * Resource Group Name: aiforgood\n",
    "    * Subscription: _there should be just one option_\n",
    "    * Resource Group Location: South Central US\n",
    "4. Click \"Create\"\n",
    "   \n",
    "A notification will appear in the top right. Click the button \"Pin to Dashboard\" to pin this resource group to your home page in the Azure portal, as you'll be referring to it frequently.\n",
    "\n",
    "## Create authorization keys for Computer Vision\n",
    "\n",
    "1. Visit https://portal.azure.com (and sign in if needed)\n",
    "2. Click \"+ Create a Resource\" (top-left corner)\n",
    "3. Click \"AI + Machine Learning\"\n",
    "4. Click \"Computer Vision\"\n",
    "    * Name: aiforgood-vision\n",
    "    * Subscription: _there should be just one option_\n",
    "    * Location: South Central US\n",
    "    * Pricing Tier: F0 (free, 20 calls per minute)\n",
    "    * Resource Group: Use existing \"aiforgood\" group\n",
    "5. Click \"Create\"\n",
    "\n",
    "After a few moments you will get a message that your keys have been generated, after which you can move to the next section.\n",
    "\n",
    "\n",
    "\n",
    "Once you've done this for all the cognitive services, save the file `keys.txt` and upload it to \n",
    "replace the existing file i## Modify the keys.txt file\n",
    "\n",
    "Edit the `keys.txt` file to provide the necessary keys. In Azure Notebooks, you select the file and press `i` to edit it directly. (Alternatively, you can download the file `keys.txt` -- highlight it in the Library view and then press `d` or click the download icon in the toolbar -- and edit it with an editor, then upload the modified file.)\n",
    "\n",
    "For the first line\n",
    "of the file, `region`, change the value to `southcentralus`. \n",
    "\n",
    "For the second line of the file, `vision,` visit your `aiforgood` resource\n",
    "group in the [Azure Portal](https://portal.azure.com?WT.mc_id=ODSC-workshop-davidsmi) and then:\n",
    "\n",
    "1. Click on the API resource for Computer Vision `aiforgood-vision`\n",
    "2. In the menu, click on \"keys\"\n",
    "3. Click the \"copy to clipboard\" next to KEY 1. (You can ignore KEY 2).\n",
    "4. Paste the key into the `vision` entry in keys.txt\n",
    "\n",
    "You can ignore the remaining lines of `keys.txt` for now.\n",
    "\n",
    "Your final `keys.txt` file will look like this, but with different (working) keys:\n",
    "\n",
    "```\n",
    "       key\n",
    "region southcentralus\n",
    "vision 7f1f01ac24064abd80970f41a90237e7\n",
    "custom 1632b49e2930430694a9bbd3ab0c0cc2\n",
    "cvpred 37eb1f0e5fd34253939350197ae3d933\n",
    "```\n",
    "\n",
    "Now you can run the R code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load some packages required by the code below. \n",
    "## These packages come pre-installed in the Azure Notebook service,\n",
    "## but if you try this code elsewhere you may need to install them first with install.packages\n",
    "library(tools)\n",
    "library(httr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The region is: southcentralus \n"
     ]
    }
   ],
   "source": [
    "## Retrieve API keys and region from keys.txt file. \n",
    "## See above for how to obtain the necessary keys and modify the file accordingly.\n",
    "\n",
    "keys <- read.table(\"keys.txt\", header=TRUE, stringsAsFactors = FALSE)\n",
    "vision_api_key <- keys[\"vision\",1]\n",
    "azure_region <- keys[\"region\",1]\n",
    "vision_api_endpoint <- paste0(\"https://\", azure_region, \".api.cognitive.microsoft.com/vision/v1.0\")\n",
    "cat(\"The region is:\",azure_region,\"\\n\")\n",
    "\n",
    "## If you see ERROR-EDIT-KEYS.txt-FILE here, you need to edit keys.txt as described in README.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here are some URLs of example images you can try out later.\n",
    "## Feel free to find other images you want to use.\n",
    "## I visited https://en.wikipedia.org/wiki/Special:Random to go to a random Wikipedia page\n",
    "## and downloaded images from there. The Large size works with API limits\n",
    "\n",
    "example_images =c(\n",
    " ## animals\n",
    " 'https://upload.wikimedia.org/wikipedia/commons/thumb/9/96/Pair_of_Merops_apiaster_feeding.jpg/1200px-Pair_of_Merops_apiaster_feeding.jpg',\n",
    " 'https://upload.wikimedia.org/wikipedia/commons/4/4f/Queenie.JPG', \n",
    " 'https://upload.wikimedia.org/wikipedia/commons/3/34/Ectopsocus_briggsi.jpg',\n",
    " ## buildings, workplaces\n",
    " 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/4b/Prze%C5%82%C4%99cz_Okraj-przejscie_graniczne.jpg/1200px-Prze%C5%82%C4%99cz_Okraj-przejscie_graniczne.jpg',\n",
    " 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/61/Wasseiges_JPG04.jpg/1200px-Wasseiges_JPG04.jpg',\n",
    " 'https://upload.wikimedia.org/wikipedia/commons/5/58/St_george_edgbaston.jpg',\n",
    " 'https://upload.wikimedia.org/wikipedia/commons/0/02/Atlanta_College_of_Art_Print_Making_Studio.jpg',\n",
    " ## non-photos \n",
    " 'https://upload.wikimedia.org/wikipedia/commons/1/15/M15_%28Ukraine%29.png',\n",
    " ## people, faces\n",
    " 'https://upload.wikimedia.org/wikipedia/en/1/1b/I_Remember_You_%28John_Hicks_album%29.jpg',\n",
    " 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/3a/FIS_Ski_Jumping_World_Cup_2014_-_Engelberg_-_20141221_-_Shohei_Tochimoto.jpg/1200px-FIS_Ski_Jumping_World_Cup_2014_-_Engelberg_-_20141221_-_Shohei_Tochimoto.jpg',\n",
    " 'https://upload.wikimedia.org/wikipedia/en/d/d7/Grover_Washabaugh.jpg',\n",
    " ## things that make the API throw errors\n",
    " 'https://upload.wikimedia.org/wikipedia/commons/3/3a/FIS_Ski_Jumping_World_Cup_2014_-_Engelberg_-_20141221_-_Shohei_Tochimoto.jpg', # too large\n",
    " 'error' #malformed URL\n",
    " )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://upload.wikimedia.org/wikipedia/commons/4/4f/Queenie.JPG \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "'a man riding a horse through a fence'"
      ],
      "text/latex": [
       "'a man riding a horse through a fence'"
      ],
      "text/markdown": [
       "'a man riding a horse through a fence'"
      ],
      "text/plain": [
       "[1] \"a man riding a horse through a fence\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.895979674074474"
      ],
      "text/latex": [
       "0.895979674074474"
      ],
      "text/markdown": [
       "0.895979674074474"
      ],
      "text/plain": [
       "[1] 0.8959797"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## In this section, we'll call the Computer Vision API manually\n",
    "## Later, we'll write a function to automate the process\n",
    "\n",
    "#image_url =\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/ef4d0bc7-2c45-4d17-afb1-9cad8f293657.jpg\"\n",
    "image_url = example_images[2] \n",
    "## feel free to try a different example, or provide a URL of your own choice\n",
    "\n",
    "visualFeatures = \"Description,Tags,Categories,Faces\"\n",
    "# choose the image information to return\n",
    "# options = \"Categories, Tags, Description, Faces, ImageType, Color, Adult\"\n",
    "\n",
    "details = \"Landmarks,Celebrities\"\n",
    "# Ask the Computer Vision API to detect names of celebrities or famous landmarks\n",
    "\n",
    "reqURL = paste0(vision_api_endpoint,\n",
    "               \"/analyze?visualFeatures=\",\n",
    "               visualFeatures,\n",
    "               \"&details=\",\n",
    "               details)\n",
    "\n",
    "APIresponse = POST(url = reqURL,\n",
    "                   content_type('application/json'),\n",
    "                   add_headers(.headers = c('Ocp-Apim-Subscription-Key' = vision_api_key)),\n",
    "                   body=list(url = image_url),\n",
    "                   encode = \"json\") \n",
    "\n",
    "df = content(APIresponse)\n",
    "\n",
    "## display caption and confidence\n",
    "cat(image_url,\"\\n\")\n",
    "df$description$captions[[1]]$text\n",
    "df$description$captions[[1]]$confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore that `df` object to see what other information is returned by the API (try: `print(df)`). We'll just be looking at the\n",
    "generated image caption for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$categories\n",
      "$categories[[1]]\n",
      "$categories[[1]]$name\n",
      "[1] \"others_\"\n",
      "\n",
      "$categories[[1]]$score\n",
      "[1] 0.00390625\n",
      "\n",
      "\n",
      "$categories[[2]]\n",
      "$categories[[2]]$name\n",
      "[1] \"outdoor_\"\n",
      "\n",
      "$categories[[2]]$score\n",
      "[1] 0.00390625\n",
      "\n",
      "$categories[[2]]$detail\n",
      "$categories[[2]]$detail$landmarks\n",
      "list()\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "$tags\n",
      "$tags[[1]]\n",
      "$tags[[1]]$name\n",
      "[1] \"tree\"\n",
      "\n",
      "$tags[[1]]$confidence\n",
      "[1] 0.9999812\n",
      "\n",
      "\n",
      "$tags[[2]]\n",
      "$tags[[2]]$name\n",
      "[1] \"outdoor\"\n",
      "\n",
      "$tags[[2]]$confidence\n",
      "[1] 0.9996668\n",
      "\n",
      "\n",
      "$tags[[3]]\n",
      "$tags[[3]]$name\n",
      "[1] \"mammal\"\n",
      "\n",
      "$tags[[3]]$confidence\n",
      "[1] 0.5555322\n",
      "\n",
      "$tags[[3]]$hint\n",
      "[1] \"animal\"\n",
      "\n",
      "\n",
      "$tags[[4]]\n",
      "$tags[[4]]$name\n",
      "[1] \"horse\"\n",
      "\n",
      "$tags[[4]]$confidence\n",
      "[1] 0.3436013\n",
      "\n",
      "\n",
      "\n",
      "$description\n",
      "$description$tags\n",
      "$description$tags[[1]]\n",
      "[1] \"outdoor\"\n",
      "\n",
      "$description$tags[[2]]\n",
      "[1] \"fence\"\n",
      "\n",
      "$description$tags[[3]]\n",
      "[1] \"photo\"\n",
      "\n",
      "$description$tags[[4]]\n",
      "[1] \"man\"\n",
      "\n",
      "$description$tags[[5]]\n",
      "[1] \"white\"\n",
      "\n",
      "$description$tags[[6]]\n",
      "[1] \"black\"\n",
      "\n",
      "$description$tags[[7]]\n",
      "[1] \"horse\"\n",
      "\n",
      "$description$tags[[8]]\n",
      "[1] \"standing\"\n",
      "\n",
      "$description$tags[[9]]\n",
      "[1] \"riding\"\n",
      "\n",
      "$description$tags[[10]]\n",
      "[1] \"park\"\n",
      "\n",
      "$description$tags[[11]]\n",
      "[1] \"old\"\n",
      "\n",
      "$description$tags[[12]]\n",
      "[1] \"young\"\n",
      "\n",
      "$description$tags[[13]]\n",
      "[1] \"holding\"\n",
      "\n",
      "$description$tags[[14]]\n",
      "[1] \"woman\"\n",
      "\n",
      "$description$tags[[15]]\n",
      "[1] \"elephant\"\n",
      "\n",
      "\n",
      "$description$captions\n",
      "$description$captions[[1]]\n",
      "$description$captions[[1]]$text\n",
      "[1] \"a man riding a horse through a fence\"\n",
      "\n",
      "$description$captions[[1]]$confidence\n",
      "[1] 0.8959797\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "$faces\n",
      "list()\n",
      "\n",
      "$requestId\n",
      "[1] \"74d36835-d257-41e0-a750-9046d0abef0b\"\n",
      "\n",
      "$metadata\n",
      "$metadata$width\n",
      "[1] 640\n",
      "\n",
      "$metadata$height\n",
      "[1] 417\n",
      "\n",
      "$metadata$format\n",
      "[1] \"Jpeg\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a function in R to apply the Computer Vision API to an image in a URL, and print out the image caption returned by the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_caption <- function(URL) {\n",
    " reqURL = paste0(vision_api_endpoint,\n",
    "                 \"/analyze?visualFeatures=Description\",\n",
    "                 \"&details=Celebrities,Landmarks\")\n",
    " \n",
    " APIresponse = POST(url = reqURL,\n",
    "                    content_type('application/json'),\n",
    "                    add_headers(.headers = c('Ocp-Apim-Subscription-Key' = vision_api_key)),\n",
    "                    body=list(url = URL),\n",
    "                    encode = \"json\") \n",
    " \n",
    " df = content(APIresponse)\n",
    " cat(URL, \"\\n\")\n",
    "\n",
    "  ## when we get Wikimedia Commons images later, we'll grab their description too, and display it if so\n",
    " if(!is.null(attr(URL,\"desc\"))) \n",
    "  cat(\"Wikimedia Commons description:\\n\", attr(URL,\"desc\"),  \"\\n\")\n",
    "\n",
    " cat(\"Vision API description:\\n\",  df$description$captions[[1]]$text,\"\\n\")\n",
    " cat(paste0(\"Confidence: \",df$description$captions[[1]]$confidence,\"\\n\"))\n",
    " invisible(df)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://media.timeout.com/images/100004257/630/472/image.jpg \n",
      "Vision API description:\n",
      " a large white building with Sacré-Cur, Paris in the background \n",
      "Confidence: 0.851741857095374\n"
     ]
    }
   ],
   "source": [
    "image_caption(\"http://media.timeout.com/images/100004257/630/472/image.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try some more images. We can write a function to return the URL of a random image in Wikimedia Commons, which will\n",
    "give us unlimited images to work with. We'll also check that the image meets the Computer Vision API restrictions \n",
    "(minimum dimensions 50x50, maximum file size 4Mb, certain image formats)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_image <- function() {\n",
    " ## Return the URL of a random image in Wikimedia Commons\n",
    " random_query <- paste0(\"https://commons.wikimedia.org/w/api.php?\",\n",
    "                        \"action=query\",\n",
    "                        \"&generator=random\", # get a random page\n",
    "                        \"&grnlimit=1\",       # return 1 page\n",
    "                        \"&grnnamespace=6\",   # category: File\n",
    "                        \"&prop=imageinfo\",\n",
    "                        \"&iiprop=url|size|extmetadata\",\n",
    "                        \"&iiurlheight=1080\",  # limit images height (sometimes)\n",
    "                        \"&format=json&formatversion=2\")\n",
    " random_response <- POST(random_query)\n",
    " output <- content(random_response)\n",
    " url <- output$query$pages[[1]]$imageinfo[[1]]$url\n",
    "\n",
    " ## check the image metadata, and throw an error if it won't work with the \n",
    " ## Computer Vision API\n",
    " ext <- tolower(file_ext(url))\n",
    " w <- output$query$pages[[1]]$imageinfo[[1]]$width\n",
    " h <- output$query$pages[[1]]$imageinfo[[1]]$height\n",
    " size <- output$query$pages[[1]]$imageinfo[[1]]$size\n",
    " desc <- output$query$pages[[1]]$imageinfo[[1]]$extmetadata$ImageDescription$value \n",
    " if(w<50 || h<50) stop(\"Image too small\") \n",
    " if(size > 4000000) stop(\"Image too large\")\n",
    " if(!(ext %in% c(\"jpg\",\"jpeg\",\"png\",\"gif\",\"bmp\"))) stop(paste(\"invalid image type:\",ext))\n",
    "\n",
    " ## In addition to the URL, return the dimensions and Wikimedia description as attributes\n",
    " attr(url, \"dims\") <- c(w=w,h=h)\n",
    " attr(url, \"desc\") <- desc\n",
    " url\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://upload.wikimedia.org/wikipedia/commons/a/a4/Heilig-Kreuz-Kirche_von_1805_in_Brockel_%28Rotenburg_%28W%C3%BCmme%29%29_IMG_3937.jpg \n",
      "Wikimedia Commons description:\n",
      " Heilig-Kreuz-Kirche von 1805 in Brockel, Niedersachsen, Deutschland \n",
      "Vision API description:\n",
      " a large brick building with a clock tower in the middle of a road \n",
      "Confidence: 0.912523714765345\n"
     ]
    }
   ],
   "source": [
    "u <- random_image()\n",
    "image_caption(u)\n",
    "\n",
    "# You might see an \"image too large\" or other error; if that happens just run this chunk again to try a different image\n",
    "# In some instances you may get no output from the Vision API. This is likely caused by an image of the wrong format or size."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
